<!DOCTYPE html>
<html lang="{{ site.lang | default: "en-US" }}">

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width,maximum-scale=2">
    <link rel="stylesheet" type="text/css" media="screen" href="{{ '/assets/css/style.css?v=' | append: site.github.build_revision | relative_url }}">

{% seo %}
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          {% if site.github.is_project_page %}
            <a id="forkme_banner" href="{{ site.github.repository_url }}">View on GitHub</a>
          {% endif %}

          <h1 id="project_title">{{ site.title | default: site.github.repository_name }}</h1>
          <h2 id="project_tagline">{{ site.description | default: site.github.project_tagline }}</h2>

          {% if site.show_downloads %}
            <section id="downloads">
              <a class="zip_download_link" href="{{ site.github.zip_url }}">Download this project as a .zip file</a>
              <a class="tar_download_link" href="{{ site.github.tar_url }}">Download this project as a tar.gz file</a>
            </section>
          {% endif %}
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h2> Deep Reinforcement Learning for Robot Navigation</h2>
        <p>Trained an agent with Twin Delayed DDPG(TD3) with a pre-planned path, 2-D lidar data, robot velocity, and the goal location. The robot was capable of reaching the destination while maintaining enough agility of avoiding obstacles even if they were very close to the pre-planned path.
        </p>
        <div class="container">
          <video class="video" controls>
            <source src="https://user-images.githubusercontent.com/8697376/121311664-3684f700-c937-11eb-9f7f-64604aaad310.mp4" type="video/mp4">
          </video>
        </div>
        <h2 id="vision-based-docking-for-omnidirectional-wheeled-mobile-robot">Vision-based docking for Omnidirectional Wheeled Mobile Robot</h2>
        <p>For this project, I designed and implemented a docking system via the Robot Operating System (ROS) that not only would enable the robot to dock at the charge station, but also would load and carry interchangeable carts and racks. This is one of the main projects I worked on at Gyro Systems.</p>
        <div class="container">
          <video class="video" controls>
            <source src="https://user-images.githubusercontent.com/8697376/121011085-cc4e4400-c7c8-11eb-80fa-8ed8376f1072.mp4" type="video/mp4">
          </video>
        </div>
        <h2 id="control-mobile-robot-with-a-unique-wheel-configuration">Control mobile robot with a unique wheel configuration</h2>
        <p>This was an extension of the aforementioned project. In this project, the two rear Mecanum wheels of a four Mecanum wheels robot were replaced by two normal passive wheels. The objective was to design and deploy a controller to drive the robot to a predefined goal position. I first designed and constructed the mechanism and the mechatronic system of the robot. Then, I developed a kinematic model of the robot and designed a control law.
        </p>
        <div class="container">
          <video class="video" controls>
            <source src="https://user-images.githubusercontent.com/8697376/121146901-f4927d00-c872-11eb-9b3f-3a929693cb22.mp4" type="video/mp4">
          </video>
        </div>

        <h2>Scanner for the Laser Engraver</h2>
        <p>
        In this project, I developed a scanning system capable of capturing the scene of the working area of the laser engraver. I also designed an image stitching software pipeline that worked efficiently and smoothly even if there are insufficient SIFT features of the working area.  
        The scanning system worked as follow: <br>
        The laser engraving head moved around the working area and took pictures using the attached camera. In the meantime, adjacent images were stitched and shown on the web.
        </p>
        
        <p>The image shows a laser engraver. The laser engraving head and camera are highlighted.</p>
        <div class="container"> 
            <img width=30% src="https://user-images.githubusercontent.com/8697376/121313127-acd62900-c938-11eb-9a05-92848d63e79c.jpeg">    
        </div>

        <p>The video shows what will be seen on the web while the laser engraving is scanning.</p>
        <div class="container">
          <video class="video" controls>
            <source src="https://user-images.githubusercontent.com/8697376/121179746-a55c4480-c892-11eb-8716-d59504dba7f4.mp4" type="video/mp4">
          </video>
        </div>
        <p>The following image is the result of stitching more than 400 images of the working area of ​​the laser engraver.</p>
        <div class="container"> 
            <img width=100% height=100% src="https://user-images.githubusercontent.com/8697376/121452209-9d56ee80-c9d1-11eb-929a-112ef8e82af1.jpeg">
        </div>

      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        {% if site.github.is_project_page %}
        <p class="copyright">{{ site.title | default: site.github.repository_name }} maintained by <a href="{{ site.github.owner_url }}">{{ site.github.owner_name }}</a></p>
        {% endif %}
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    {% if site.google_analytics %}
      <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', '{{ site.google_analytics }}', 'auto');
        ga('send', 'pageview');
      </script>
    {% endif %}
  </body>
</html>
